/* * Copyright (c) 2009 Chase Douglas * * This program is free software; you can redistribute it and/or * modify it under the terms of the GNU General Public License version 2 * as published by the Free Software Foundation. * * This program is distributed in the hope that it will be useful, * but WITHOUT ANY WARRANTY; without even the implied warranty of * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the * GNU General Public License for more details. * * You should have received a copy of the GNU General Public License * along with this program; if not, write to the Free Software * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA. */#include <stdlib.h>#include <stdio.h>#include <string.h>#include <android/log.h>#include <jni.h>#include "libavformat/avformat.h"#ifdef HAVE_AV_CONFIG_H#undef HAVE_AV_CONFIG_H#endif#include "libavcodec/avcodec.h"#include "libavutil/mathematics.h"#define INBUF_SIZE 4096#define AUDIO_INBUF_SIZE 20480#define AUDIO_REFILL_THRESH 4096#define CODEC_TYPE_AUDIO AVMEDIA_TYPE_AUDIO#define CODEC_TYPE_VIDEO AVMEDIA_TYPE_VIDEO#define PKT_FLAG_KEY AV_PKT_FLAG_KEYstatic AVStream *add_output_stream(AVFormatContext *output_format_context, AVStream *input_stream) {    AVCodecContext *input_codec_context;    AVCodecContext *output_codec_context;    AVStream *output_stream;    output_stream = av_new_stream(output_format_context, 0);    if (!output_stream) {        fprintf(stderr, "Could not allocate stream\n");        exit(1);    }    input_codec_context = input_stream->codec;    output_codec_context = output_stream->codec;    output_codec_context->codec_id = input_codec_context->codec_id;    output_codec_context->codec_type = input_codec_context->codec_type;    output_codec_context->codec_tag = input_codec_context->codec_tag;    output_codec_context->bit_rate = input_codec_context->bit_rate;    output_codec_context->extradata = input_codec_context->extradata;    output_codec_context->extradata_size = input_codec_context->extradata_size;    if(av_q2d(input_codec_context->time_base) * input_codec_context->ticks_per_frame > av_q2d(input_stream->time_base) && av_q2d(input_stream->time_base) < 1.0/1000) {        output_codec_context->time_base = input_codec_context->time_base;        output_codec_context->time_base.num *= input_codec_context->ticks_per_frame;    }    else {        output_codec_context->time_base = input_stream->time_base;    }    switch (input_codec_context->codec_type) {        case CODEC_TYPE_AUDIO:            output_codec_context->channel_layout = input_codec_context->channel_layout;            output_codec_context->sample_rate = input_codec_context->sample_rate;            output_codec_context->channels = input_codec_context->channels;            output_codec_context->frame_size = input_codec_context->frame_size;            if ((input_codec_context->block_align == 1 && input_codec_context->codec_id == CODEC_ID_MP3) || input_codec_context->codec_id == CODEC_ID_AC3) {                output_codec_context->block_align = 0;            }            else {                output_codec_context->block_align = input_codec_context->block_align;            }            break;        case CODEC_TYPE_VIDEO:            output_codec_context->pix_fmt = input_codec_context->pix_fmt;            output_codec_context->width = input_codec_context->width;            output_codec_context->height = input_codec_context->height;            output_codec_context->has_b_frames = input_codec_context->has_b_frames;            if (output_format_context->oformat->flags & AVFMT_GLOBALHEADER) {                output_codec_context->flags |= CODEC_FLAG_GLOBAL_HEADER;            }            break;    default:        break;    }    return output_stream;}int write_index_file(const char index[], const char tmp_index[], const unsigned int segment_duration, const char output_prefix[], const char http_prefix[], const unsigned int first_segment, const unsigned int last_segment, const int end, const int window) {    FILE *index_fp;    char *write_buf;    unsigned int i;    index_fp = fopen(tmp_index, "w");    if (!index_fp) {        fprintf(stderr, "Could not open temporary m3u8 index file (%s), no index file will be created\n", tmp_index);        return -1;    }    write_buf = malloc(sizeof(char) * 1024);    if (!write_buf) {        fprintf(stderr, "Could not allocate write buffer for index file, index file will be invalid\n");        fclose(index_fp);        return -1;    }    if (window) {        snprintf(write_buf, 1024, "#EXTM3U\n#EXT-X-TARGETDURATION:%u\n#EXT-X-MEDIA-SEQUENCE:%u\n", segment_duration, first_segment);    }    else {        snprintf(write_buf, 1024, "#EXTM3U\n#EXT-X-TARGETDURATION:%u\n", segment_duration);    }    if (fwrite(write_buf, strlen(write_buf), 1, index_fp) != 1) {        fprintf(stderr, "Could not write to m3u8 index file, will not continue writing to index file\n");        free(write_buf);        fclose(index_fp);        return -1;    }    for (i = first_segment; i <= last_segment; i++) {        snprintf(write_buf, 1024, "#EXTINF:%u,\n%s%s-%u.ts\n", segment_duration, http_prefix, output_prefix, i);        if (fwrite(write_buf, strlen(write_buf), 1, index_fp) != 1) {            fprintf(stderr, "Could not write to m3u8 index file, will not continue writing to index file\n");            free(write_buf);            fclose(index_fp);            return -1;        }    }    if (end) {        snprintf(write_buf, 1024, "#EXT-X-ENDLIST\n");        if (fwrite(write_buf, strlen(write_buf), 1, index_fp) != 1) {            fprintf(stderr, "Could not write last file and endlist tag to m3u8 index file\n");            free(write_buf);            fclose(index_fp);            return -1;        }    }    free(write_buf);    fclose(index_fp);    return rename(tmp_index, index);}static void video_encode_example(const char *filename){    AVCodec *codec;    AVCodecContext *c= NULL;    int i, out_size, size, x, y, outbuf_size;    FILE *f;    AVFrame *picture;    uint8_t *outbuf, *picture_buf;    printf("Video encoding\n");    /* find the mpeg1 video encoder */    codec = avcodec_find_encoder(CODEC_ID_MPEG4);    if (!codec) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "codec not found");        fprintf(stderr, "codec not found\n");        exit(1);    }    c= avcodec_alloc_context();    picture= avcodec_alloc_frame();    /* put sample parameters */    c->bit_rate = 400000;    /* resolution must be a multiple of two */    c->width = 352;    c->height = 288;    /* frames per second */    c->time_base= (AVRational){1,25};    c->gop_size = 10; /* emit one intra frame every ten frames */    c->max_b_frames=1;    c->pix_fmt = PIX_FMT_YUV420P;    /* open it */    if (avcodec_open(c, codec) < 0) {        fprintf(stderr, "could not open codec\n");        exit(1);    }    f = fopen(filename, "wb");    if (!f) {        fprintf(stderr, "could not open %s\n", filename);        exit(1);    }    /* alloc image and output buffer */    outbuf_size = 100000;    outbuf = malloc(outbuf_size);    size = c->width * c->height;    picture_buf = malloc((size * 3) / 2); /* size for YUV 420 */    picture->data[0] = picture_buf;    picture->data[1] = picture->data[0] + size;    picture->data[2] = picture->data[1] + size / 4;    picture->linesize[0] = c->width;    picture->linesize[1] = c->width / 2;    picture->linesize[2] = c->width / 2;    /* encode 1 second of video */    for(i=0;i<25;i++) {        fflush(stdout);        /* prepare a dummy image */        /* Y */        for(y=0;y<c->height;y++) {            for(x=0;x<c->width;x++) {                picture->data[0][y * picture->linesize[0] + x] = x + y + i * 3;            }        }        /* Cb and Cr */        for(y=0;y<c->height/2;y++) {            for(x=0;x<c->width/2;x++) {                picture->data[1][y * picture->linesize[1] + x] = 128 + y + i * 2;                picture->data[2][y * picture->linesize[2] + x] = 64 + x + i * 5;            }        }        /* encode the image */        out_size = avcodec_encode_video(c, outbuf, outbuf_size, picture);        printf("encoding frame %3d (size=%5d)\n", i, out_size);        fwrite(outbuf, 1, out_size, f);    }    /* get the delayed frames */    for(; out_size; i++) {        fflush(stdout);        out_size = avcodec_encode_video(c, outbuf, outbuf_size, NULL);        printf("write frame %3d (size=%5d)\n", i, out_size);        fwrite(outbuf, 1, out_size, f);    }    /* add sequence end code to have a real mpeg file */    outbuf[0] = 0x00;    outbuf[1] = 0x00;    outbuf[2] = 0x01;    outbuf[3] = 0xb7;    fwrite(outbuf, 1, 4, f);    fclose(f);    free(picture_buf);    free(outbuf);    avcodec_close(c);    av_free(c);    av_free(picture);    printf("\n");}/* * Video decoding example */static void pgm_save(unsigned char *buf, int wrap, int xsize, int ysize,                     char *filename){    FILE *f;    int i;    f=fopen(filename,"w");    fprintf(f,"P5\n%d %d\n%d\n",xsize,ysize,255);    for(i=0;i<ysize;i++)        fwrite(buf + i * wrap,1,xsize,f);    fclose(f);}static void video_decode_example(const char *outfilename, const char *filename){    AVCodec *codec;    AVCodecContext *c= NULL;    int frame, got_picture, len;    FILE *f;    AVFrame *picture;    uint8_t inbuf[INBUF_SIZE + FF_INPUT_BUFFER_PADDING_SIZE];    char buf[1024];    AVPacket avpkt;		    av_init_packet(&avpkt);    /* set end of buffer to 0 (this ensures that no overreading happens for damaged mpeg streams) */    memset(inbuf + INBUF_SIZE, 0, FF_INPUT_BUFFER_PADDING_SIZE);    printf("Video decoding\n");    /* find the mpeg1 video decoder */    codec = avcodec_find_decoder(CODEC_ID_MPEG4);    if (!codec) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "codec not found");        fprintf(stderr, "codec not found\n");        exit(1);    }    c= avcodec_alloc_context();    picture= avcodec_alloc_frame();    if(codec->capabilities&CODEC_CAP_TRUNCATED)        c->flags|= CODEC_FLAG_TRUNCATED; /* we do not send complete frames */    /* For some codecs, such as msmpeg4 and mpeg4, width and height       MUST be initialized there because this information is not       available in the bitstream. */    /* open it */    if (avcodec_open(c, codec) < 0) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "not open codec");        fprintf(stderr, "could not open codec\n");        exit(1);    }    /* the codec gives us the frame size, in samples */    f = fopen(filename, "rb");	    if (!f) {			__android_log_print(ANDROID_LOG_DEBUG, "test", "could not open %s", filename);        fprintf(stderr, "could not open %s\n", filename);        exit(1);    }    frame = 0;    for(;;) {        avpkt.size = fread(inbuf, 1, INBUF_SIZE, f);        if (avpkt.size == 0)            break;        /* NOTE1: some codecs are stream based (mpegvideo, mpegaudio)           and this is the only method to use them because you cannot           know the compressed data size before analysing it.           BUT some other codecs (msmpeg4, mpeg4) are inherently frame           based, so you must call them with all the data for one           frame exactly. You must also initialize 'width' and           'height' before initializing them. */        /* NOTE2: some codecs allow the raw parameters (frame size,           sample rate) to be changed at any frame. We handle this, so           you should also take care of it */        /* here, we use a stream based decoder (mpeg1video), so we           feed decoder and see if it could decode a frame */        avpkt.data = inbuf;        while (avpkt.size > 0) {            len = avcodec_decode_video2(c, picture, &got_picture, &avpkt);            if (len < 0) {				__android_log_print(ANDROID_LOG_DEBUG, "test", "Error while decoding frame");                fprintf(stderr, "Error while decoding frame %d\n", frame);                exit(1);            }            if (got_picture) {                printf("saving frame %3d\n", frame);                fflush(stdout);                /* the picture is allocated by the decoder. no need to                   free it */				__android_log_print(ANDROID_LOG_DEBUG, "test", "snprintf");                snprintf(buf, sizeof(buf), outfilename, frame);                pgm_save(picture->data[0], picture->linesize[0],                         c->width, c->height, buf);                frame++;            }            avpkt.size -= len;            avpkt.data += len;        }    }    /* some codecs, such as MPEG, transmit the I and P frame with a       latency of one frame. You must do the following to have a       chance to get the last frame of the video */    avpkt.data = NULL;    avpkt.size = 0;    len = avcodec_decode_video2(c, picture, &got_picture, &avpkt);    if (got_picture) {        printf("saving last frame %3d\n", frame);        fflush(stdout);        /* the picture is allocated by the decoder. no need to           free it */		__android_log_print(ANDROID_LOG_DEBUG, "test", "snprintf");        snprintf(buf, sizeof(buf), outfilename, frame);        pgm_save(picture->data[0], picture->linesize[0],                 c->width, c->height, buf);        frame++;    }    fclose(f);    avcodec_close(c);    av_free(c);    av_free(picture);    printf("\n");}int Segmenter(int argc, char argv[6][100]){    const char *input;    const char *output_prefix;	const char *mp4_output;	char temp[100];    double segment_duration;    char *segment_duration_check;    const char *index;    char *tmp_index;    const char *http_prefix;    long max_tsfiles = 0;    char *max_tsfiles_check;    double prev_segment_time = 0;    unsigned int output_index = 1;    AVInputFormat *ifmt;    AVOutputFormat *ofmt;    AVFormatContext *ic = NULL;    AVFormatContext *oc;    AVStream *video_st;    AVStream *audio_st;    AVCodec *codec;    char *output_filename;    char *remove_filename;    int video_index;    int audio_index;    unsigned int first_segment = 1;    unsigned int last_segment = 0;    int write_index = 1;    int decode_done;    char *dot;    int ret;    int i;    int remove_file;	    if (argc < 6 || argc > 7) {        fprintf(stderr, "Usage: %s <input MPEG-TS file> <segment duration in seconds> <output MPEG-TS file prefix> <output m3u8 index file> <http prefix> [<segment window size>]\n", argv[0]);        exit(1);    }    av_register_all();	    input = argv[1];    if (!strcmp(input, "-")) {        input = "pipe:";    }	//strcpy(temp, argv[1]);			//i=strlen(temp);	////temp[i-5]='d';	//temp[i-4]='.';	//temp[i-3]='p';	//temp[i-2]='g';	//temp[i-1]='m';	//input = temp;	//avcodec_init();	//avcodec_register_all();	//video_decode_example(input , mp4_output);		//video_encode_example(mp4_output);	//return;    segment_duration = strtod(argv[2], &segment_duration_check);	    if (segment_duration_check == argv[2] || segment_duration == HUGE_VAL || segment_duration == -HUGE_VAL) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Segment duration time (%s) invalid\n", argv[2]);        fprintf(stderr, "Segment duration time (%s) invalid\n", argv[2]);        exit(1);    }	    output_prefix = argv[3];    index = argv[4];    http_prefix=argv[5];    if (argc == 7) {        max_tsfiles = strtol(argv[6], &max_tsfiles_check, 10);        if (max_tsfiles_check == argv[6] || max_tsfiles < 0 || max_tsfiles >= INT_MAX) {            fprintf(stderr, "Maximum number of ts files (%s) invalid\n", argv[6]);            exit(1);        }    }		    remove_filename = malloc(sizeof(char) * (strlen(output_prefix) + 15));    if (!remove_filename) {        fprintf(stderr, "Could not allocate space for remove filenames");        exit(1);    }	    output_filename = malloc(sizeof(char) * (strlen(output_prefix) + 15));    if (!output_filename) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not allocate space for output filenames");        fprintf(stderr, "Could not allocate space for output filenames\n");        exit(1);    }	    tmp_index = malloc(strlen(index) + 2);    if (!tmp_index) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not allocate space for temporary index filename");        fprintf(stderr, "Could not allocate space for temporary index filename\n");        exit(1);    }	    strncpy(tmp_index, index, strlen(index) + 2);    dot = strrchr(tmp_index, '/');    dot = dot ? dot + 1 : tmp_index;    for (i = strlen(tmp_index) + 1; i > dot - tmp_index; i--) {        tmp_index[i] = tmp_index[i - 1];    }    *dot = '.';	    ifmt = av_find_input_format("mpegts");    if (!ifmt) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not find MPEG-TS demuxer");        fprintf(stderr, "Could not find MPEG-TS demuxer\n");        exit(1);    }    ret = av_open_input_file(&ic, input, ifmt, 0, NULL);    if (ret != 0) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not open input file, make sure it is an mpegts file: %d\n", ret);        fprintf(stderr, "Could not open input file, make sure it is an mpegts file: %d\n", ret);        exit(1);    }    if (av_find_stream_info(ic) < 0) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not read stream information");        fprintf(stderr, "Could not read stream information\n");        exit(1);    }    ofmt = av_guess_format("mpegts", NULL, NULL);    if (!ofmt) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not find MPEG-TS muxer");        fprintf(stderr, "Could not find MPEG-TS muxer\n");        exit(1);    }    oc = avformat_alloc_context();    if (!oc) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not allocated output context");        fprintf(stderr, "Could not allocated output context");        exit(1);    }    oc->oformat = ofmt;    video_index = -1;    audio_index = -1;	    for (i = 0; i < ic->nb_streams && (video_index < 0 || audio_index < 0); i++) {        switch (ic->streams[i]->codec->codec_type) {            case CODEC_TYPE_VIDEO:                video_index = i;                ic->streams[i]->discard = AVDISCARD_NONE;                video_st = add_output_stream(oc, ic->streams[i]);                break;            case CODEC_TYPE_AUDIO:                audio_index = i;                ic->streams[i]->discard = AVDISCARD_NONE;                audio_st = add_output_stream(oc, ic->streams[i]);                break;            default:                ic->streams[i]->discard = AVDISCARD_ALL;                break;        }    }    if (av_set_parameters(oc, NULL) < 0) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Invalid output format parameters");        fprintf(stderr, "Invalid output format parameters\n");        exit(1);    }    dump_format(oc, 0, output_prefix, 1);    codec = avcodec_find_decoder(video_st->codec->codec_id);    if (!codec) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not find video decoder, key frames will not be honored");        fprintf(stderr, "Could not find video decoder, key frames will not be honored\n");    }    if (avcodec_open(video_st->codec, codec) < 0) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not open video decoder, key frames will not be honored");        fprintf(stderr, "Could not open video decoder, key frames will not be honored\n");    }    snprintf(output_filename, strlen(output_prefix) + 15, "%s-%u.ts", output_prefix, output_index++);    if (url_fopen(&oc->pb, output_filename, URL_WRONLY) < 0) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not open '%s'", output_filename);        fprintf(stderr, "Could not open '%s'\n", output_filename);        exit(1);    }    if (av_write_header(oc)) {		__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not write mpegts header to first output file");        fprintf(stderr, "Could not write mpegts header to first output file\n");        exit(1);    }    write_index = !write_index_file(index, tmp_index, segment_duration, output_prefix, http_prefix, first_segment, last_segment, 0, max_tsfiles);	    do {        double segment_time;        AVPacket packet;		char tempchar[4];        decode_done = av_read_frame(ic, &packet);		        if (decode_done < 0) {            break;        }        if (av_dup_packet(&packet) < 0) {            fprintf(stderr, "Could not duplicate packet");			__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not duplicate packet");            av_free_packet(&packet);            break;        }		//__android_log_print(ANDROID_LOG_DEBUG, "test", "packet.flags : %d, PKT_FLAG_KEY : %d", packet.flags, PKT_FLAG_KEY);s		if (packet.stream_index == video_index && (packet.flags & PKT_FLAG_KEY)) {            segment_time = (double)video_st->pts.val * video_st->time_base.num / video_st->time_base.den;        }        else if (video_index < 0) {            segment_time = (double)audio_st->pts.val * audio_st->time_base.num / audio_st->time_base.den;        }        else {            segment_time = prev_segment_time;        }		        if (segment_time - prev_segment_time >= segment_duration) {            put_flush_packet(oc->pb);            url_fclose(oc->pb);            if (max_tsfiles && (int)(last_segment - first_segment) >= max_tsfiles - 1) {                remove_file = 1;                first_segment++;            }            else {                remove_file = 0;            }            if (write_index) {                write_index = !write_index_file(index, tmp_index, segment_duration, output_prefix, http_prefix, first_segment, ++last_segment, 0, max_tsfiles);            }            if (remove_file) {                snprintf(remove_filename, strlen(output_prefix) + 15, "%s-%u.ts", output_prefix, first_segment - 1);				                remove(remove_filename);            }            snprintf(output_filename, strlen(output_prefix) + 15, "%s-%u.ts", output_prefix, output_index++);            if (url_fopen(&oc->pb, output_filename, URL_WRONLY) < 0) {				__android_log_print(ANDROID_LOG_DEBUG, "test", "Could not open %s", output_filename);                fprintf(stderr, "Could not open '%s'\n", output_filename);                break;            }            prev_segment_time = segment_time;        }        ret = av_interleaved_write_frame(oc, &packet);        if (ret < 0) {			__android_log_print(ANDROID_LOG_DEBUG, "test", "Warning: Could not write frame of stream");            fprintf(stderr, "Warning: Could not write frame of stream\n");        }        else if (ret > 0) {			__android_log_print(ANDROID_LOG_DEBUG, "test" ,"End of stream requested");            fprintf(stderr, "End of stream requested\n");            av_free_packet(&packet);            break;        }        av_free_packet(&packet);    } while (!decode_done);    av_write_trailer(oc);    avcodec_close(video_st->codec);    for(i = 0; i < oc->nb_streams; i++) {        av_freep(&oc->streams[i]->codec);        av_freep(&oc->streams[i]);    }    url_fclose(oc->pb);    av_free(oc);    if (max_tsfiles && (int)(last_segment - first_segment) >= max_tsfiles - 1) {        remove_file = 1;        first_segment++;    }    else {        remove_file = 0;    }    if (write_index) {        write_index_file(index, tmp_index, segment_duration, output_prefix, http_prefix, first_segment, ++last_segment, 1, max_tsfiles);    }    if (remove_file) {        snprintf(remove_filename, strlen(output_prefix) + 15, "%s-%u.ts", output_prefix, first_segment - 1);        remove(remove_filename);    }	__android_log_print(ANDROID_LOG_DEBUG, "test", "End");    return 0;}// vim:sw=4:tw=4:ts=4:ai:expandtabstatic void video_encode(const char *filename, const char *inputfilename){    AVCodec *codec;    AVCodecContext *c= NULL;    int i, out_size, size, x, y, outbuf_size, read_size;    FILE *f, *fin;    AVFrame *picture;    uint8_t *outbuf, *picture_buf;	int clip_width = 353;	int clip_height = 288;	__android_log_print(ANDROID_LOG_DEBUG, "encode", "Video encoding");        /* find the mpeg1 video encoder */    codec = avcodec_find_encoder(CODEC_ID_H264);    if (!codec) {		__android_log_print(ANDROID_LOG_DEBUG, "encode", "codec not found");        fprintf(stderr, "codec not found\n");        exit(1);    }    c= avcodec_alloc_context();    picture= avcodec_alloc_frame();	//   Dev	c= avcodec_alloc_context();	c->coder_type = FF_CODER_TYPE_VLC; // coder = 1	c->flags|=CODEC_FLAG_LOOP_FILTER; // flags=+loop	c->me_cmp|= 1; // cmp=+chroma, where CHROMA = 1	c->partitions|=X264_PART_I8X8|X264_PART_I4X4|X264_PART_P8X8|X264_PART_B8X8|X264_PART_P4X4; // partitions=+parti8x8+parti4x4+partp8x8+partb8x8//	c->partitions|=X264_PART_I4X4|X264_PART_P8X8|X264_PART_B8X8; // partitions=+parti8x8+parti4x4+partp8x8+partb8x8	c->me_method=ME_HEX; // me_method=hex	c->me_subpel_quality = 0; // subq=7	c->me_range = 16; // me_range=16	c->gop_size = 250; // g=250	c->keyint_min = 25; // keyint_min=25	c->scenechange_threshold = 40; // sc_threshold=40	c->i_quant_factor = 0.71; // i_qfactor=0.71	c->b_frame_strategy = 1; // b_strategy=1	c->qcompress = 0.6; // qcomp=0.6	c->qmin = 10; // qmin=10	c->qmax = 51; // qmax=51	c->max_qdiff = 4; // qdiff=4	c->max_b_frames = 3; // bf=3	c->refs = 3; // refs=3	c->directpred = 1; // directpred=1	c->trellis = 1; // trellis=1	c->flags2|=CODEC_FLAG2_FASTPSKIP; // flags2=+bpyramid+mixed_refs+wpred+dct8x8+fastpskip	c->weighted_p_pred = 0; // wpredp=2	c->bit_rate = 32000;	c->width = 352;	c->height = 288;	c->time_base.num = 1;	c->time_base.den = 30;	c->pix_fmt = PIX_FMT_YUV420P; //	c->dsp_mask = (FF_MM_MMX | FF_MM_MMXEXT | FF_MM_SSE);	c->rc_lookahead = 0;	c->max_b_frames = 0;	c->b_frame_strategy =1;	c->chromaoffset = 0;	c->thread_count =1;	c->bit_rate = (int)(128000.f * 0.80f);	c->bit_rate_tolerance = (int) (128000.f * 0.20f);	c->gop_size = 25; // Each 3 seconds	    /* put sample parameters *///    c->bit_rate = 400000;    /* resolution must be a multiple of two *///    c->width = 352;//    c->height = 288;    /* frames per second *///    c->time_base= (AVRational){1,25};//    c->gop_size = 10; /* emit one intra frame every ten frames *///    c->max_b_frames=1;//    c->pix_fmt = PIX_FMT_YUV420P;    /* open it */    if (avcodec_open(c, codec) < 0) {		__android_log_print(ANDROID_LOG_DEBUG, "encode", "could not open codec");        exit(1);    }    f = fopen(filename, "wb");    if (!f) {		__android_log_print(ANDROID_LOG_DEBUG, "encode", "could not open %s\n", filename);        exit(1);    }	fin = fopen(inputfilename, "rb");    if (!f) {		__android_log_print(ANDROID_LOG_DEBUG, "encode", "could not open %s\n", inputfilename);        exit(1);    }    /* alloc image and output buffer */    outbuf_size = 100000;    outbuf = (uint8_t*)malloc(outbuf_size);    size = c->width * c->height;	size = avpicture_get_size(PIX_FMT_YUV420P, clip_width, clip_height);    picture_buf = (uint8_t*)malloc((size * 3) / 2); /* size for YUV 420 */    picture->data[0] = picture_buf;    picture->data[1] = picture->data[0] + size;    picture->data[2] = picture->data[1] + size / 4;    picture->linesize[0] = c->width;    picture->linesize[1] = c->width / 2;    picture->linesize[2] = c->width / 2;    /* encode 1 second of video */    for(i=0;i<400;i++) {        fflush(stdout);        //read 1 frame to buffer		fread(picture->data[0], c->width * c->height, 1, fin);		fread(picture->data[1], c->width * c->height/4, 1, fin);		fread(picture->data[2], c->width * c->height/4, 1, fin);		picture->pts = AV_NOPTS_VALUE;		//encode frame        /* encode the image */        out_size = avcodec_encode_video(c, outbuf, outbuf_size, picture);		__android_log_print(ANDROID_LOG_DEBUG, "encode", "encoding frame %3d (size=%5d)\n", i, out_size);        fwrite(outbuf, 1, out_size, f);    }    /* get the delayed frames */    for(; out_size; i++) {        fflush(stdout);        out_size = avcodec_encode_video(c, outbuf, outbuf_size, NULL);		__android_log_print(ANDROID_LOG_DEBUG, "encode", "write frame %3d (size=%5d)\n", i, out_size);        printf("write frame %3d (size=%5d)\n", i, out_size);        fwrite(outbuf, 1, out_size, f);    }    /* add sequence end code to have a real mpeg file */    outbuf[0] = 0x00;    outbuf[1] = 0x00;    outbuf[2] = 0x01;    outbuf[3] = 0xb7;    fwrite(outbuf, 1, 4, f);    fclose(f);    free(picture_buf);    free(outbuf);    avcodec_close(c);    av_free(c);    av_free(picture);}int Java_com_mangosteen_streaming_HlsActivity_TSh264encoder(JNIEnv *env, jobject obj, jobjectArray args){	int i = 0;	int argc = 0;	char **argv = NULL;	/* must be called before using avcodec lib */	avcodec_init();	/* register all the codecs */    	avcodec_register_all();		if (args != NULL) {		argc = (*env)->GetArrayLength(env, args);		argv = (char **) malloc(sizeof(char *) * argc);		for(i=0;i<argc;i++)		{			jstring str = (jstring)(*env)->GetObjectArrayElement(env, args, i);			argv[i] = (char *)(*env)->GetStringUTFChars(env, str, NULL);   		}	}		video_encode(argv[0], argv[1]);    	return 0;}int Java_com_mangosteen_streaming_HlsActivity_TSsegmenter(JNIEnv *env, jobject thiz, jobjectArray filePath){	//const jbyte *str;	//int result;	char str[6][100];	int i;			for(i=1;i<6;i++)	{		const jbyte *strj;		jstring currentObj;		//__android_log_print(ANDROID_LOG_DEBUG, "test", "00");		currentObj = (jstring)(*env)->GetObjectArrayElement(env, filePath, i);		//__android_log_print(ANDROID_LOG_DEBUG, "test", "01");		//k = (*env)->GetStringUTFLength(env, filePath[i]);		strj = (*env)->GetStringUTFChars(env, currentObj, 0);		//__android_log_print(ANDROID_LOG_DEBUG, "test", strj);		strcpy(str[i], strj);	}		//result = 	//__android_log_print(ANDROID_LOG_DEBUG, "test", "02");	//return Segmenter(6, str);	//return (*env)->NewStringUTF(env, "Hello from JNI !");	return Segmenter(6, str);}